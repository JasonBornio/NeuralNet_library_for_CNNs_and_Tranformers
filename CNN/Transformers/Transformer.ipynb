{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from network import components as cnn\n",
    "from network import functional as F\n",
    "from nlp import functional as nlp\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"C:\\\\Users\\\\jugwu\\\\Documents\\\\justins_work\\\\CNN\\\\cleanData\\\\\"\n",
    "PADDING = '<pad>'\n",
    "START = '<start>'\n",
    "END = '<end>'\n",
    "NORM = None\n",
    "\n",
    "num_samples = 5\n",
    "max_seq = 10\n",
    "EMBEDDINGS = 'embeddings8'\n",
    "\n",
    "#cl.clean(\"text2\", \"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file, num:int=1, max_sequence_length:int=1):\n",
    "    with open(DATAPATH + file + \".txt\", 'r',encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data_points = []\n",
    "    data_labels = []\n",
    "\n",
    "    for i, sentence in enumerate(lines):\n",
    "        if i==0:\n",
    "            continue\n",
    "        if i >= num:\n",
    "            break\n",
    "\n",
    "        sentence = re.sub(\"\\n\", \"\", sentence)\n",
    "\n",
    "        words = sentence.split(' ')\n",
    "        words.append(END)\n",
    "        words.insert(0, START)\n",
    "\n",
    "\n",
    "        for j in range(len(words) - max_sequence_length):\n",
    "            data_labels.append(words[j+1:j + max_sequence_length +1])\n",
    "            data_points.append(words[j:j + max_sequence_length])\n",
    "\n",
    "    for data, label in zip(data_points, data_labels):\n",
    "        print(f\"data: {data}, label: {label}\")\n",
    "        \n",
    "    return data_points, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['<start>', 'tanjiros', 'attack', 'completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower'], label: ['tanjiros', 'attack', 'completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank']\n",
      "data: ['tanjiros', 'attack', 'completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank'], label: ['attack', 'completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to']\n",
      "data: ['attack', 'completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to'], label: ['completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash']\n",
      "data: ['completely', 'severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash'], label: ['severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a']\n",
      "data: ['severs', 'enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a'], label: ['enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible']\n",
      "data: ['enmus', 'neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible'], label: ['neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream']\n",
      "data: ['neck', 'causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream'], label: ['causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and']\n",
      "data: ['causing', 'the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and'], label: ['the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break']\n",
      "data: ['the', 'lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break'], label: ['lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break', 'into']\n",
      "data: ['lower', 'rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break', 'into'], label: ['rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break', 'into', 'pieces']\n",
      "data: ['rank', 'to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break', 'into', 'pieces'], label: ['to', 'unleash', 'a', 'terrible', 'scream', 'and', 'break', 'into', 'pieces', '<end>']\n",
      "data: ['<start>', 'the', 'piece', 'of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and'], label: ['the', 'piece', 'of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke']\n",
      "data: ['the', 'piece', 'of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke'], label: ['piece', 'of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are']\n",
      "data: ['piece', 'of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are'], label: ['of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on']\n",
      "data: ['of', 'the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on'], label: ['the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins']\n",
      "data: ['the', 'demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins'], label: ['demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to']\n",
      "data: ['demonic', 'train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to'], label: ['train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall']\n",
      "data: ['train', 'that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall'], label: ['that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways']\n",
      "data: ['that', 'tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways'], label: ['tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways', 'with']\n",
      "data: ['tanjiro', 'and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways', 'with'], label: ['and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways', 'with', 'the']\n",
      "data: ['and', 'inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways', 'with', 'the'], label: ['inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers']\n",
      "data: ['inosuke', 'are', 'on', 'begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers'], label: ['are', 'on', 'begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier']\n",
      "data: ['are', 'on', 'begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier'], label: ['on', 'begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound']\n",
      "data: ['on', 'begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound'], label: ['begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from']\n",
      "data: ['begins', 'to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from'], label: ['to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from', 'the']\n",
      "data: ['to', 'fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from', 'the'], label: ['fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from', 'the', 'train']\n",
      "data: ['fall', 'sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from', 'the', 'train'], label: ['sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer']\n",
      "data: ['sideways', 'with', 'the', 'formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer'], label: ['with', 'the', 'formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly']\n",
      "data: ['with', 'the', 'formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly'], label: ['the', 'formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring']\n",
      "data: ['the', 'formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring'], label: ['formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring', 'with']\n",
      "data: ['formers', 'earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring', 'with'], label: ['earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring', 'with', 'pain']\n",
      "data: ['earlier', 'wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring', 'with', 'pain'], label: ['wound', 'from', 'the', 'train', 'engineer', 'suddenly', 'flaring', 'with', 'pain', '<end>']\n",
      "data: ['<start>', 'inosuke', 'notes', 'this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him'], label: ['inosuke', 'notes', 'this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to']\n",
      "data: ['inosuke', 'notes', 'this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to'], label: ['notes', 'this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect']\n",
      "data: ['notes', 'this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect'], label: ['this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the']\n",
      "data: ['this', 'with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the'], label: ['with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers']\n",
      "data: ['with', 'concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers'], label: ['concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers', 'his']\n",
      "data: ['concern', 'but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers', 'his'], label: ['but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers', 'his', 'only']\n",
      "data: ['but', 'tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers', 'his', 'only'], label: ['tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers', 'his', 'only', 'concern']\n",
      "data: ['tanjiro', 'tells', 'him', 'to', 'protect', 'the', 'passengers', 'his', 'only', 'concern'], label: ['tells', 'him', 'to', 'protect', 'the', 'passengers', 'his', 'only', 'concern', 'living']\n",
      "data: ['tells', 'him', 'to', 'protect', 'the', 'passengers', 'his', 'only', 'concern', 'living'], label: ['him', 'to', 'protect', 'the', 'passengers', 'his', 'only', 'concern', 'living', 'so']\n",
      "data: ['him', 'to', 'protect', 'the', 'passengers', 'his', 'only', 'concern', 'living', 'so'], label: ['to', 'protect', 'the', 'passengers', 'his', 'only', 'concern', 'living', 'so', 'that']\n",
      "data: ['to', 'protect', 'the', 'passengers', 'his', 'only', 'concern', 'living', 'so', 'that'], label: ['protect', 'the', 'passengers', 'his', 'only', 'concern', 'living', 'so', 'that', 'the']\n",
      "data: ['protect', 'the', 'passengers', 'his', 'only', 'concern', 'living', 'so', 'that', 'the'], label: ['the', 'passengers', 'his', 'only', 'concern', 'living', 'so', 'that', 'the', 'train']\n",
      "data: ['the', 'passengers', 'his', 'only', 'concern', 'living', 'so', 'that', 'the', 'train'], label: ['passengers', 'his', 'only', 'concern', 'living', 'so', 'that', 'the', 'train', 'engineer']\n",
      "data: ['passengers', 'his', 'only', 'concern', 'living', 'so', 'that', 'the', 'train', 'engineer'], label: ['his', 'only', 'concern', 'living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\"]\n",
      "data: ['his', 'only', 'concern', 'living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\"], label: ['only', 'concern', 'living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become']\n",
      "data: ['only', 'concern', 'living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become'], label: ['concern', 'living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become', 'a']\n",
      "data: ['concern', 'living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become', 'a'], label: ['living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become', 'a', 'murderer']\n",
      "data: ['living', 'so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become', 'a', 'murderer'], label: ['so', 'that', 'the', 'train', 'engineer', \"dosen't\", 'become', 'a', 'murderer', '<end>']\n",
      "data: ['<start>', 'the', 'young', 'demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance'], label: ['the', 'young', 'demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance', 'from']\n",
      "data: ['the', 'young', 'demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance', 'from'], label: ['young', 'demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance', 'from', 'the']\n",
      "data: ['young', 'demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance', 'from', 'the'], label: ['demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable']\n",
      "data: ['demon', 'slayer', 'is', 'cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable'], label: ['slayer', 'is', 'cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable', 'train']\n",
      "data: ['slayer', 'is', 'cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable', 'train'], label: ['is', 'cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck']\n",
      "data: ['is', 'cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck'], label: ['cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with']\n",
      "data: ['cast', 'a', 'short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with'], label: ['a', 'short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke']\n",
      "data: ['a', 'short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke'], label: ['short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately']\n",
      "data: ['short', 'distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately'], label: ['distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending']\n",
      "data: ['distance', 'from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending'], label: ['from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending', 'to']\n",
      "data: ['from', 'the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending', 'to'], label: ['the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending', 'to', 'him']\n",
      "data: ['the', 'inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending', 'to', 'him'], label: ['inevitable', 'train', 'wreck', 'with', 'inosuke', 'immediately', 'attending', 'to', 'him', '<end>']\n",
      "data: 620, labels: 620\n"
     ]
    }
   ],
   "source": [
    "#data,labels = nlp.load_data(\"clean\", num=2)\n",
    "data2,labels2 = load_data(\"clean\", num=num_samples, max_sequence_length=max_seq)\n",
    "print(f\"data: {np.size(data2)}, labels: {np.size(labels2)}\")\n",
    "tokens, vocab = nlp.tokenise(\"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd(data, labels, file):\n",
    "    vectors, tags = nlp.load_vectors(\"embeddings8\")\n",
    "    corpus = []\n",
    "    \n",
    "    for dat, lab in zip(data, labels):\n",
    "        data_points = []\n",
    "        data_labels = []\n",
    "        for d, l in zip(dat,lab):\n",
    "            data_points.append(vectors[tags.index(d)])\n",
    "            label = torch.zeros(np.shape(tags)[0], dtype=torch.float)\n",
    "            label[tags.index(l)] = 1\n",
    "            data_labels.append(label)\n",
    "        temp = []\n",
    "        temp.append(torch.stack(data_points))\n",
    "        temp.append(torch.stack(data_labels))\n",
    "        corpus.append(temp)\n",
    "        \n",
    "    #print(corpus[0])\n",
    "    #print(np.shape(corpus[0]))\n",
    "\n",
    "    #corpus = torch.stack(corpus)\n",
    "            \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10, 24])\n",
      "torch.Size([30, 10, 419])\n",
      "torch.Size([30, 10, 24])\n",
      "torch.Size([30, 10, 419])\n",
      "torch.Size([2, 10, 24])\n",
      "torch.Size([2, 10, 419])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = np.shape(tokens)[0]\n",
    "train_data = embedd(data2,labels2, EMBEDDINGS)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=30, shuffle=True)\n",
    "\n",
    "for batch in trainloader:\n",
    "    print(batch[0].size())\n",
    "    print(batch[1].size())\n",
    "    #print(batch[0])\n",
    "    #print(batch[1])\n",
    "\n",
    "vocab_size = np.shape(batch[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork():\n",
    "    def __init__(self, d_model:int=512, ffn_hidden:int=2048, drop_prob:float=0.1):\n",
    "\n",
    "        self.fc1 = cnn.FullyConnected(d_model, ffn_hidden,norm=NORM)\n",
    "        self.relu = cnn.ReLu()\n",
    "        self.fc2 = cnn.FullyConnected(ffn_hidden, d_model,norm=NORM)\n",
    "        self.dropout = cnn.Dropout(drop_prob=drop_prob)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, _input, training:bool = True):\n",
    "        self.training = training\n",
    "        residual = _input\n",
    "\n",
    "        output = self.fc1.forward(_input)\n",
    "        output = self.relu.forward(output)\n",
    "        output = self.fc2.forward(output)\n",
    "       \n",
    "        if self.training:\n",
    "            output = self.dropout.forward(output)\n",
    "    \n",
    "        output = cnn.layer_norm(output + residual)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def back(self, gradient, param):\n",
    "\n",
    "        residual = gradient\n",
    "        \n",
    "        if self.training:\n",
    "            gradient = self.dropout.back(gradient, param)\n",
    "\n",
    "        gradient = self.fc2.back(gradient, param)\n",
    "        gradient = self.relu.back(gradient, param)\n",
    "        gradient = self.fc1.back(gradient, param)\n",
    "        gradient += residual\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetworkCONV():\n",
    "    def __init__(self, d_model:int=512, ffn_hidden:int=2048, max_seq_length:int=10):\n",
    "\n",
    "        self.conv1 = cnn.Convolution_1D(input_size=max_seq_length, channels=ffn_hidden)#cnn.FullyConnected(d_model, ffn_hidden,norm=None)\n",
    "        self.relu = cnn.ReLu()\n",
    "        self.conv2 = cnn.Convolution_1D(input_size=max_seq_length, channels=d_model)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def forward(self, _input):\n",
    "\n",
    "        residual = _input\n",
    "        _input = torch.transpose(_input, -2,-1)\n",
    "        output = self.conv1.forward(_input)\n",
    "        output = self.relu.forward(output)\n",
    "        output = self.conv2.forward(output)\n",
    "        output = torch.transpose(output, -2,-1)\n",
    "    \n",
    "        norm_output = cnn.layer_norm(output + residual)\n",
    "\n",
    "        return norm_output\n",
    "    \n",
    "    def back(self, gradient, param):\n",
    "\n",
    "        residual = gradient\n",
    "        gradient = torch.transpose(gradient, -2,-1)\n",
    "        gradient = self.conv2.back(gradient, param)\n",
    "        gradient = self.relu.back(gradient, param)\n",
    "        gradient = self.conv1.back(gradient, param)\n",
    "        gradient = torch.transpose(gradient, -2,-1)\n",
    "        gradient += residual\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention():\n",
    "    def __init__(self, d_model:int=512, num_heads:int=8,drop_prob:float=0.1):\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.linear_q = cnn.FullyConnected(d_model, d_model,norm=NORM)\n",
    "        self.linear_k = cnn.FullyConnected(d_model, d_model,norm=NORM)\n",
    "        self.linear_v = cnn.FullyConnected(d_model, d_model,norm=NORM)\n",
    "        self.linear_out = cnn.FullyConnected(d_model, d_model,norm=NORM)\n",
    "        self.softmax = cnn.Softmax()\n",
    "        self.dropout = cnn.Dropout(drop_prob=drop_prob)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def forward(self, _input, mask=None,show:bool=False, training:bool = True):\n",
    "\n",
    "        self.plot = show\n",
    "        self.training=training\n",
    "\n",
    "        self.batch_size, self.max_seq_length, self.d_model = _input.size()\n",
    "        self.len_q = int(self.d_model/self.num_heads)\n",
    "\n",
    "        residual = _input\n",
    "        \n",
    "        linear_Q = self.linear_q.forward(_input) #20 X 10 X 24\n",
    "        linear_K = self.linear_k.forward(_input)\n",
    "        linear_V = self.linear_v.forward(_input)\n",
    "\n",
    "        Q_heads = linear_Q.reshape(self.batch_size, self.max_seq_length, self.num_heads, self.len_q) #20 X 10 X 8 X 3\n",
    "        Q_heads = Q_heads.permute(0, 2, 1, 3) #20 X 8 X 10 X 3\n",
    "        K_heads = linear_K.reshape(self.batch_size, self.max_seq_length, self.num_heads, self.len_q)\n",
    "        K_heads = K_heads.permute(0, 2, 1, 3)\n",
    "        V_heads = linear_V.reshape(self.batch_size, self.max_seq_length, self.num_heads, self.len_q)\n",
    "        V_heads = V_heads.permute(0, 2, 1, 3)\n",
    "\n",
    "        values = self.scaled_dot_product(Q_heads, K_heads, V_heads,mask=mask) #20 X 8 X 10 X 3\n",
    "        \n",
    "        values = values.reshape(self.batch_size, self.max_seq_length, self.d_model) #20 X 10 X 24\n",
    "\n",
    "        output = self.linear_out.forward(values)\n",
    "\n",
    "        if self.training:\n",
    "            output = self.dropout.forward(output)\n",
    "            \n",
    "        output = cnn.layer_norm(output + residual)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def back(self, gradient, param):\n",
    "\n",
    "        #print(torch.sum(gradient))\n",
    "\n",
    "        residual = gradient\n",
    "        #gradient = cnn.layer_norm(gradient)\n",
    "        \n",
    "        if self.training:\n",
    "            gradient = self.dropout.back(gradient, param)\n",
    "        \n",
    "        gradient = self.linear_out.back(gradient, param)\n",
    "\n",
    "        #scaled dot product stuff_______________\n",
    "\n",
    "        gradient = gradient.reshape(self.batch_size, self.num_heads, self.max_seq_length, self.len_q)\n",
    "\n",
    "        #der Attention / der V\n",
    "        d_V = self.scores.transpose(-2,-1) @ gradient#tick\n",
    "\n",
    "        #der Attention / der Scores\n",
    "        gradient = gradient @ self.V.transpose(-2,-1)#tick\n",
    "\n",
    "        #der Scores / der Dot\n",
    "        gradient = self.softmax.back(gradient, param)\n",
    "\n",
    "        #der Dot / der Q\n",
    "        d_Q = (gradient @ self.K/self.d_k)#tick\n",
    "\n",
    "        #der Dot / der K\n",
    "        d_K = (gradient.transpose(-2,-1) @ self.Q/self.d_k)#tick\n",
    "\n",
    "        #print(f\"q: {d_Q.size()}, k: {d_K.size()}, v: {d_V.size()}\")\n",
    "\n",
    "        d_Q = d_Q.permute(0, 2, 1, 3)\n",
    "        d_K = d_K.permute(0, 2, 1, 3)\n",
    "        d_V = d_V.permute(0, 2, 1, 3)\n",
    "        \n",
    "        #print(f\"q: {d_Q.size()}, k: {d_K.size()}, v: {d_V.size()}\")\n",
    "\n",
    "        d_Q = d_Q.reshape(self.batch_size, self.max_seq_length, self.d_model)\n",
    "        d_K = d_K.reshape(self.batch_size, self.max_seq_length, self.d_model)\n",
    "        d_V = d_V.reshape(self.batch_size, self.max_seq_length, self.d_model)\n",
    "        \n",
    "        print(f\"q: {d_Q.sum()}, k: {d_K.sum()}, v: {d_V.sum()}\")\n",
    "        \n",
    "        #scaled dot product stuff_______________\n",
    "        \n",
    "\n",
    "        grad_Q = self.linear_q.back(d_Q, param)\n",
    "        grad_K = self.linear_k.back(d_K, param)\n",
    "        grad_V = self.linear_v.back(d_V, param)\n",
    "\n",
    "        gradient = grad_Q + grad_K + grad_V\n",
    "\n",
    "        #print(torch.sum(gradient))\n",
    "\n",
    "        gradient += residual\n",
    "        \n",
    "        #print(torch.sum(gradient))\n",
    "\n",
    "        return gradient\n",
    "    \n",
    "    def scaled_dot_product(self,Q,K,V, mask=None):\n",
    "\n",
    "        full_mask = torch.zeros((self.max_seq_length, self.max_seq_length)) + float('-inf')\n",
    "        full_mask = torch.triu(full_mask, diagonal=1) \n",
    "        full_mask = full_mask.unsqueeze(0).unsqueeze(0).expand(self.batch_size, self.num_heads,-1,-1)\n",
    "        #print(f\"Q: {Q}\")\n",
    "        #print(f\"V: {V}\")\n",
    "\n",
    "        self.d_k = self.len_q ** (1/2)\n",
    "        self.Q, self.K, self.V = Q, K, V\n",
    "\n",
    "        attention_weights = (Q @ K.transpose(-2,-1))/self.d_k\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand(-1,self.num_heads,-1,-1)\n",
    "            full_mask = full_mask +  mask\n",
    "\n",
    "        attention_weights += full_mask\n",
    "\n",
    "        self.scores = self.softmax.forward(attention_weights)\n",
    "\n",
    "        if self.plot:\n",
    "            for i in range(self.num_heads):\n",
    "                plt.imshow(self.scores[-1][i])\n",
    "                plt.show()\n",
    "                break\n",
    "        #print(self.scores[-1][0])\n",
    "        attention = self.scores @ V\n",
    "\n",
    "        return attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer():\n",
    "    def __init__(self, d_model:int=512, num_heads:int=8, ffn_hidden:int=2048,drop_prob:float=0.1):\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads, drop_prob=drop_prob)\n",
    "        self.ffn_net = FeedForwardNetwork(d_model=d_model, ffn_hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def forward(self, _input, mask=None, show:bool=False, training:bool = True):\n",
    "\n",
    "        out = self.self_attention.forward(_input, mask=mask,show=show, training=training)\n",
    "        out = self.ffn_net.forward(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def back(self, gradient, param):\n",
    "\n",
    "        gradient = self.ffn_net.back(gradient, param)\n",
    "        gradient = self.self_attention.back(gradient, param)\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel():\n",
    "    def __init__(self, d_model:int=512, num_heads:int=8, ffn_hidden:int=2048, num_layers:int=2, vocab_size:int=10, drop_prob:float=0.1):\n",
    "\n",
    "        self.layers = [DecoderLayer(d_model=d_model, num_heads=num_heads, ffn_hidden=ffn_hidden, drop_prob=drop_prob) for _ in range(num_layers)]\n",
    "        self.linear = cnn.FullyConnected(d_model, vocab_size, norm=NORM)\n",
    "        self.softmax = cnn.Softmax()\n",
    "        self.postional_encoding = cnn.PostionalEncoding()\n",
    "        self.init_pad = True\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, _input, show:bool=False, training:bool = True):\n",
    "        \n",
    "        if self.init_pad:\n",
    "            self.pad_tensor = torch.zeros_like(_input[0][0], dtype=torch.float)\n",
    "            self.init_pad = False\n",
    "\n",
    "        mask = (_input == self.pad_tensor.unsqueeze(0).unsqueeze(0).expand(_input.size()[0], _input.size()[1],-1)).float()\n",
    "        mask = (mask @ torch.transpose(mask,-2,-1))\n",
    "        #print(pad_mask)\n",
    "        mask = torch.where(torch.clamp(mask, max=1) == 1, float('-inf'), 0)\n",
    "        self.mask = torch.tril(mask, diagonal=-1) \n",
    "        #embedd\n",
    "\n",
    "        #encode\n",
    "        out = self.postional_encoding.encode(_input)\n",
    "\n",
    "        #decoder layers\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out, mask=self.mask, show=show, training=training)\n",
    "        \n",
    "        #linear classifier\n",
    "        out = self.linear.forward(out)\n",
    "        out = self.softmax.forward(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, gradient, lr:float=0.001, optim=None,optim_lr:float=0.9, optim_b1:float=0.9, optim_b2:float=0.999):\n",
    "\n",
    "        \n",
    "        _parameters = {\n",
    "            'lr' : lr,\n",
    "            'optimiser' : optim,\n",
    "            'optimiser_lr' : optim_lr,\n",
    "            'optimiser_b1' : optim_b1,\n",
    "            'optimiser_b2' : optim_b2\n",
    "        }\n",
    "\n",
    "        gradient = self.softmax.back(gradient, _parameters)\n",
    "        gradient = self.linear.back(gradient, _parameters)\n",
    "\n",
    "        for layer in self.layers[::-1]:\n",
    "            gradient = layer.back(gradient, _parameters)\n",
    "\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainManager(object):\n",
    "    def __init__(self, train, test, val = None):\n",
    "        self.train_loader = train\n",
    "        self.test_loader = test\n",
    "        self.val_loader = val\n",
    "        self.history = {\n",
    "            'train_loss' : [],\n",
    "            'validation_loss' : [],\n",
    "            'train_accuracy' : [],\n",
    "            'validation_accuracy' : [],\n",
    "            'test_accuracy' : []\n",
    "        }\n",
    "        return\n",
    "    \n",
    "    def one_hot(self, number):\n",
    "        result = torch.zeros(10, dtype=torch.float)\n",
    "        result[number] = 1.0\n",
    "        return result\n",
    "\n",
    "    def train(self, _model, loss_func = F.MSELoss, epochs:int=1, lr:float=0.001, optim_b1:float=0.9, optim_b2:float=0.999, num_batches:int=1, optimiser='adam', decay:bool=False, loss_plot:bool=False):\n",
    "       \n",
    "        count = 0\n",
    "\n",
    "        if decay:\n",
    "            decay = lr/epochs\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            batch_count = 0\n",
    "\n",
    "            #batches = int(3000 / 128)\n",
    "\n",
    "            for train_batch in self.train_loader:\n",
    "\n",
    "                size = np.shape(train_batch)[0]\n",
    "                \n",
    "\n",
    "                if decay:\n",
    "                    lr *= (1/(1 + decay * (epoch * num_batches + total)))\n",
    "\n",
    "                count+=1\n",
    "                total+=1\n",
    "\n",
    "                _input = train_batch[0]\n",
    "                _label = train_batch[1]\n",
    "\n",
    "                result = _model.forward(_input)\n",
    "                _loss = loss_func.calculate(result, _label)\n",
    "                _model.backward(loss_func.back(), lr=lr, optim=optimiser, optim_b1=optim_b1, optim_b2=optim_b2)\n",
    "                self.history['train_loss'].append(_loss)\n",
    "\n",
    "                \n",
    "                corr_ten = (torch.argmax(result, dim=-1) == torch.argmax(_label, dim=-1)).float()\n",
    "                correct += torch.mean(corr_ten) \n",
    "                self.history['train_accuracy'].append((correct/total) * 100)\n",
    "\n",
    "                if loss_plot:\n",
    "                    self.plot_loss_accuracy()\n",
    "\n",
    "                #if self.history['train_accuracy'][-1] > 15.0:\n",
    "                    #break\n",
    "                print(f\"Epoch: {epoch}, it: {count}/{size * epochs} [train_loss: {self.history['train_loss'][-1]:.7f}], [train_accuracy: {self.history['train_accuracy'][-1]:.1f}]\")\n",
    "        \n",
    "        self.trained_model = _model\n",
    "\n",
    "        return\n",
    "    \n",
    "    def test(self, num_batches:int=100, num_examples:int=1):\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for test_batch in tqdm(self.test_loader):\n",
    "            size = np.shape(test_batch)[0]\n",
    "            total+=1\n",
    "            \n",
    "            _input = test_batch[0]\n",
    "            _label = test_batch[1]\n",
    "\n",
    "            result = self.trained_model.forward(_input)    \n",
    "            corr_ten = (torch.argmax(result, dim=-1) == torch.argmax(_label, dim=-1)).float()\n",
    "            correct += torch.mean(corr_ten) \n",
    "\n",
    "            self.history['test_accuracy'].append((correct/total) * 100)\n",
    "\n",
    "        result = self.trained_model.forward_show(_input, _label, num_examples)   \n",
    "        print(f\"[test_accuracy: {sum(self.history['test_accuracy'])/len(self.history['test_accuracy'])}]\")\n",
    "\n",
    "        return\n",
    "    \n",
    "    def plot_loss_accuracy(self):\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(2)\n",
    "        \n",
    "        ax[0].plot(self.history['train_loss'], label=\"train_loss\")\n",
    "        #ax[0].plot(self.history['val_loss'], label=\"validation_loss\")\n",
    "        #ax[0].set_ylim(0, 0.2)\n",
    "        #ax[0].set_xlim(0, self.data_size)\n",
    "        ax[0].legend()\n",
    "        \n",
    "        ax[1].plot(self.history['train_accuracy'], label=\"train_accuracy\")\n",
    "        #ax[1].plot(self.history['valid_accuracy'], label=\"validation_accuracy\")\n",
    "        ax[1].set_ylim(0, 100)\n",
    "        #ax[1].set_xlim(0, self.data_size)\n",
    "        ax[1].legend()\n",
    "        plt.show()\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, it: 12/8 [train_loss: 0.0160769], [train_accuracy: 1.1]\n"
     ]
    }
   ],
   "source": [
    "model = DecoderModel(d_model=24, num_layers=2, vocab_size=vocab_size, drop_prob=0.1)\n",
    "\n",
    "loss_function = F.BinaryCrossEntropyLoss()\n",
    "trial = TrainManager(train=trainloader, test=trainloader)\n",
    "trial.train(model, loss_func=loss_function, num_batches=20, epochs=4, lr=0.0002, loss_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_old(_model, _start = '<start>', num:int=10, _show=False):\n",
    "    start = [PADDING] * num\n",
    "    #print(start)\n",
    "    start[-1] = _start\n",
    "    #print(start)\n",
    "    _vectors, _vocab = nlp.load_vectors(EMBEDDINGS)\n",
    "    start_vect = []\n",
    "    for word in start:\n",
    "        start_vect.append(_vectors[vocab.index(word)])\n",
    "    \n",
    "    start_vect = torch.stack(start_vect)\n",
    "    start_vect = start_vect.unsqueeze(0)\n",
    "    #print(start_vect.size())\n",
    "    sentence = _start \n",
    "    \n",
    "    for i in range(num):\n",
    "        token_index = torch.argmax(_model.forward(start_vect,show=False,training=False)[:,i])\n",
    "        temp = start_vect[:, 1:].clone()\n",
    "        start_vect[:, :-1] = temp\n",
    "        start_vect[:, -1] = _vectors[token_index]\n",
    "        sentence = sentence + ' ' + _vocab[token_index]\n",
    "        if _show:\n",
    "            for index in torch.argmax(_model.forward(start_vect,training=False)[0], dim=1):\n",
    "                print(_vocab[index])\n",
    "            print(\"______________\")\n",
    "\n",
    "    print(sentence)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(_model, _start = '<start>', num:int=10, show:bool=False):\n",
    "    start = [PADDING] * (num + 1)\n",
    "    #print(start)\n",
    "    start[0] = _start\n",
    "    #print(start)\n",
    "    _vectors, _vocab = nlp.load_vectors(EMBEDDINGS)\n",
    "    start_vect = []\n",
    "    for word in start:\n",
    "        start_vect.append(_vectors[vocab.index(word)])\n",
    "    \n",
    "    start_vect = torch.stack(start_vect)\n",
    "    start_vect = start_vect.unsqueeze(0)\n",
    "    #print(start_vect.size())\n",
    "    sentence = _start \n",
    "    \n",
    "    for i in range(num):\n",
    "        token_index = torch.argmax(_model.forward(start_vect,training=False)[:,i])\n",
    "        start_vect[:, i+1] = _vectors[token_index]\n",
    "        sentence = sentence + ' ' + _vocab[token_index]\n",
    "        if show:\n",
    "            for index in torch.argmax(_model.forward(start_vect,training=False)[0], dim=1):\n",
    "                print(_vocab[index])\n",
    "            print(\"______________\")\n",
    "\n",
    "\n",
    "    print(sentence)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> are are are are are are are are are are\n",
      "tanjiros are are are are are are are are are are\n"
     ]
    }
   ],
   "source": [
    "generate(model, num=max_seq)\n",
    "generate(model, num=max_seq, _start='tanjiros')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "differ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
